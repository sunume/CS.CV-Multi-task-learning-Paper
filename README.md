# CS.CV-Multi-task-learning-Paper

Multi-task Loss
1. Multi-task learning as multiobjective optimization.
2. Gradient normalization for adaptive loss balancing in deep multitask networks.
3. [MultiNet++: Multi-Stream Feature Aggregation and Geometric Loss Strategyfor Multi-Task Learning](https://arxiv.org/pdf/1904.08492v2.pdf)(A Interesting Atempt with Geometric Loss Strategy)

Multi-task Architecture Research
1. [Which Tasks Should Be Learned Together in Multi-task Learning?](https://arxiv.org/pdf/1905.07553v2.pdf)
2. [Continual and Multi-Task Architecture Search.](https://arxiv.org/pdf/1906.05226v1.pdf)
3. [Branched Multi-Task Networks: Deciding What Layers To Share](https://arxiv.org/pdf/1904.02920v1.pdf)
4. [End-to-End Multi-Task Learning with Attention](https://arxiv.org/pdf/1803.10704v2.pdf)
